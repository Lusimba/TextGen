{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lusimba/TextGen/blob/master/TextGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zXx15hTTfMA",
        "colab_type": "code",
        "outputId": "00b83155-82a5-4eaf-fbaa-e971cce04993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 188 (delta 0), reused 0 (delta 0), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (188/188), 4.36 MiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFJ3RI8yT8GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"gpt-2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNNF6E15URJY",
        "colab_type": "code",
        "outputId": "58986237-e275-4c45-da6c-94e0a0ea2e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.12.0"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpLeKoOsr9MC",
        "colab_type": "code",
        "outputId": "19bf5930-41c1-4fdf-bdae-e70f184c7e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJvQk9UGsE_W",
        "colab_type": "code",
        "outputId": "b7524536-b523-4169-a949-90501a749dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 600kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 34.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 630kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:28, 50.4Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 5.44Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 34.4Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 23.5Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64tLA48QsM0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUxBHtivsqnZ",
        "colab_type": "code",
        "outputId": "aa2656e1-4307-47eb-b5d0-101f0b39f986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "os.chdir('src')\n",
        "!pwd\n",
        "!ls\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2/src\n",
            "encoder.py\t\t\t    model.py\n",
            "generate_unconditional_samples.py   sample.py\n",
            "interactive_conditional_samples.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc_2g5l-0BTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\n",
        "# !apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\n",
        "# !apt-get update\n",
        "# !apt-get install cuda\n",
        "!pip3 install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKxIMPB4svAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import model, sample, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHEk7gKbtB2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interact_model(\n",
        "\n",
        "    model_name,\n",
        "\n",
        "    seed,\n",
        "\n",
        "    nsamples,\n",
        "\n",
        "    batch_size,\n",
        "\n",
        "    length,\n",
        "\n",
        "    temperature,\n",
        "\n",
        "    top_k,\n",
        "\n",
        "    models_dir\n",
        "\n",
        "):\n",
        "\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "\n",
        "    if batch_size is None:\n",
        "\n",
        "        batch_size = 1\n",
        "\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "\n",
        "    hparams = model.default_hparams()\n",
        "\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "\n",
        "\n",
        "    if length is None:\n",
        "\n",
        "        length = hparams.n_ctx // 2\n",
        "\n",
        "    elif length > hparams.n_ctx:\n",
        "\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        tf.set_random_seed(seed)\n",
        "\n",
        "        output = sample.sample_sequence(\n",
        "\n",
        "            hparams=hparams, length=length,\n",
        "\n",
        "            context=context,\n",
        "\n",
        "            batch_size=batch_size,\n",
        "\n",
        "            temperature=temperature, top_k=top_k\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "\n",
        "\n",
        "        while True:\n",
        "\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "\n",
        "            while not raw_text:\n",
        "\n",
        "                print('Prompt should not be empty!')\n",
        "\n",
        "                raw_text = input(\"Model prompt >>> \")\n",
        "\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "\n",
        "            generated = 0\n",
        "\n",
        "            for _ in range(nsamples // batch_size):\n",
        "\n",
        "                out = sess.run(output, feed_dict={\n",
        "\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "\n",
        "                })[:, len(context_tokens):]\n",
        "\n",
        "                for i in range(batch_size):\n",
        "\n",
        "                    generated += 1\n",
        "\n",
        "                    text = enc.decode(out[i])\n",
        "\n",
        "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "\n",
        "                    print(text)\n",
        "\n",
        "            print(\"=\" * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNvjTODGyM_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "40ab1ec0-405b-42b5-c7fd-826635f1b919"
      },
      "source": [
        "interact_model('345M', None, 1, 1, 300, 1, 0, '/content/gpt-2/models')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prompt >>> You recently requested assistance from our online support center.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Please talk to your Magic Support Team.'' After 300 results have been uploaded or received, we'll have another technician in contact.\n",
            "\n",
            "How to Report an Alarm While Driving Through an Egress Route\n",
            "\n",
            "To report a car malfunctioning affecting your driver or passenger(s) while in residential areas, please contact:\n",
            "\n",
            "User: [email protected]\n",
            "\n",
            "How to View a Location(s) on Google Maps\n",
            "\n",
            "To view and compass an existing location, please visit the location details of the Independent Lab at Wikimedia Commons.<|endoftext|>An international team of physicians including leading neuroscientists has found that treatment with alternative medicines can halt the molecular alterations characteristic of Alzheimer's disease.\n",
            "\n",
            "With sufficient spare energy, advanced age-related cerebral tissue atrophy—the accumulation of abnormal brain cells—can become irreversible. In this and many other neurological conditions, medication to reverse this disease can reverse brain damage and allow the progression of new therapies.A University of Illinois – Shady Campus brain and behavioral scientist, neuroscientist Murray Rossi and his colleagues decided to look at studying compound such as cannabidiol (CBD) and omega-3 polyunsaturated fatty acids (PUFAs): a non-trickery health ingredient found in a wide array of plant-based foods. The researchers used methylene blue, a fluorescent dye that can capture exposure to light across species, in order to examine brain damage caused by the presence of CBD, an oil derived from hemp. \"\n",
            "================================================================================\n",
            "Model prompt >>> I love Bob Marley's songs. They make my mornings peaceful and calm.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " As long as there's darkness, noble will always follow.\n",
            "\n",
            "Communication\n",
            "\n",
            "I miss being a pen/sound machine/music teacher. Allowing pupils to learn is what you want to hinder. So ideas did not come to me but my rather hazy conception of values, but for me that isn't the problem. Thematically it also came about from some things I felt were superficial, such as college etiquette and values. I left everything dear to us all we gathers was fine and simple. This was so important to me because sometimes I need something more. People call innovations innovative as they require the unburdening of suffering.\n",
            "\n",
            "Unfortunately, the entire discipline was horribly conservative, while still imposing pressure of some sort, such as marking time and boundaries, in order to please chastise them and act as friends. I don't remember how many hip drinking movements this made but they needed to reach out to the palates of 13 year olds to see if they recover the commitment to drinking, more than many of other real businesses, we knew.\n",
            "\n",
            "Studying intelligence and various occupational skills and latest proprietary systems, everything actually had connection with unrequited feelings of love, sadness, regret or disgust – ect.\n",
            "\n",
            "Challenging baselines\n",
            "\n",
            "The only standards that entailed is the least surprise one or more. That doesn't mean that friendships must be bonded about things, but there needs to be a relationship along strict boundaries.\n",
            "\n",
            "Wants to want to\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}